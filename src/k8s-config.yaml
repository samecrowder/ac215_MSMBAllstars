# DEPRECATED FOR k8s-deploy/tasks/main.yml

# ConfigMap for environment variables
apiVersion: v1
kind: ConfigMap
metadata:
  name: tennis-env
data:
  ENV: "prod"
  PORT: "8000"
  API_PORT: "8000"
  MODEL_PORT: "8001"
  MODEL_HOST: "probability-model"
  LLM_PORT: "8002"
  LLM_HOST: "llm"
  OLLAMA_HOST: "ollama"
  GCP_PROJECT: "tennis-match-predictor"
  GCP_ZONE: "us-central1-a"
  GCS_BUCKET_NAME: "msmballstars-data"
  DATA_FOLDER: "version1"
  DATA_FILE: "combined_atp_matches.csv"
---
# API Service
apiVersion: v1
kind: Service
metadata:
  name: api
spec:
  selector:
    app: api
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
  type: LoadBalancer
---
apiVersion: networking.gke.io/v1
kind: ManagedCertificate
metadata:
  name: managed-cert
spec:
  domains:
    - tennis-match-predictor.claycoleman.us
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: managed-cert-ingress
  annotations:
    # this is the name of the static IP that was created via command line
    kubernetes.io/ingress.global-static-ip-name: api-ip
    # this is the name of the SSL cert that was created above, 
    # it points to a domain name that has a DNS record pointing to the above static IP 
    networking.gke.io/managed-certificates: managed-cert
    kubernetes.io/ingress.class: "gce"  
spec:
  defaultBackend:
    service:
      name: api
      port:
        number: 8000
---
# API Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
  annotations:
    kubernetes.io/change-cause: "Deploy {{ IMAGE_TAG }}"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
      annotations:
        rollme: "{{ IMAGE_TAG }}"
    spec:
      containers:
        - name: api
          image: "gcr.io/tennis-match-predictor/api:{{ IMAGE_TAG }}"
          ports:
            - containerPort: 8000
          env:
            - name: PORT
              value: "8000"
          envFrom:
            - configMapRef:
                name: tennis-env
          volumeMounts:
            - name: gcp-key
              mountPath: "/secrets"
              readOnly: true
          imagePullPolicy: Always
      volumes:
        - name: gcp-key
          secret:
            secretName: gcp-credentials
---
# Probability Model Service
apiVersion: v1
kind: Service
metadata:
  name: probability-model
spec:
  selector:
    app: probability-model
  ports:
    - protocol: TCP
      port: 8001
      targetPort: 8001
---
# Probability Model Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: probability-model
  annotations:
    kubernetes.io/change-cause: "Deploy {{ IMAGE_TAG }}"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: probability-model
  template:
    metadata:
      labels:
        app: probability-model
      annotations:
        rollme: "{{ IMAGE_TAG }}"
    spec:
      containers:
        - name: probability-model
          image: "gcr.io/tennis-match-predictor/probability-model:{{ IMAGE_TAG }}"
          ports:
            - containerPort: 8001
          env:
            - name: PORT
              value: "8001"
            - name: DATA_FILE
              value: "training_data_lookback=10.pkl"
            - name: WEIGHTS_FILE
              value: "prob_model.pt"
            - name: HIDDEN_SIZE
              value: "32"
            - name: NUM_LAYERS
              value: "2"
            - name: CUDA_VISIBLE_DEVICES
              value: ""
            - name: TORCH_DEVICE
              value: "cpu"
          envFrom:
            - configMapRef:
                name: tennis-env
          volumeMounts:
            - mountPath: /secrets
              name: gcp-key
              readOnly: true
          imagePullPolicy: Always
      volumes:
        - name: gcp-key
          secret:
            secretName: gcp-credentials
---
# LLM Service
apiVersion: v1
kind: Service
metadata:
  name: llm
spec:
  selector:
    app: llm
  ports:
    - protocol: TCP
      port: 8002
      targetPort: 8002
---
# LLM Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm
  annotations:
    kubernetes.io/change-cause: "Deploy {{ IMAGE_TAG }}"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm
  template:
    metadata:
      labels:
        app: llm
      annotations:
        rollme: "{{ IMAGE_TAG }}"
    spec:
      containers:
        - name: llm
          image: "gcr.io/tennis-match-predictor/llm:{{ IMAGE_TAG }}"
          ports:
            - containerPort: 8002
          env:
            - name: PORT
              value: "8002"
            - name: OLLAMA_HOST
              valueFrom:
                configMapKeyRef:
                  name: tennis-env
                  key: OLLAMA_HOST
          envFrom:
            - configMapRef:
                name: tennis-env
          volumeMounts:
            - name: gcp-key
              mountPath: "/secrets"
              readOnly: true
          imagePullPolicy: Always
      volumes:
        - name: gcp-key
          secret:
            secretName: gcp-credentials
---
# Ollama Service
apiVersion: v1
kind: Service
metadata:
  name: ollama
spec:
  selector:
    app: ollama
  ports:
    - protocol: TCP
      port: 11434
      targetPort: 11434
---
# Ollama Deployment
# we need to run ollama on a node with a GPU to speed up inference
# since we only have quota for 1 GPU, however, when we try to spin up a new instance,
# it will fail with a quota error.
# so we need to run ollama on the same node as the API, which does not require a GPU.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  annotations:
    kubernetes.io/change-cause: "Deploy {{ IMAGE_TAG }}"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
      annotations:
        rollme: "{{ IMAGE_TAG }}"
    spec:
      # require that the deployment's node has a GPU
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      containers:
        - name: ollama
          image: "gcr.io/tennis-match-predictor/ollama:{{ IMAGE_TAG }}"
          ports:
            - containerPort: 11434
          resources:
            limits:
              nvidia.com/gpu: 1
          volumeMounts:
            - name: ollama-storage
              mountPath: /root/.ollama
          imagePullPolicy: Always
      volumes:
        - name: ollama-storage
          emptyDir: {}
